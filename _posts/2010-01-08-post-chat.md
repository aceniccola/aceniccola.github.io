---
title: "Mamaba + Latent Space Models"
categories:
  - Blog
tags:
  - chat
  - Post Formats
---

Learning about these non-traditional transformers only further ingrained my belief that there must be a better way to reach actual intellegnt systems then just contually pushing transformers around. 

It seems to me that we are machines that have learned how to model the world and then act on that model. This allows us to act multimodally and gives us the ability to reason in distinct tasks. We can say, 'there is a bear' and run away from the bear because we have ingrained inside of us the ability to create, inside ourselves a world of our perception. When a bear (or another threat) enters this world we immediate realkize it and, without having to be told by an outside force, try to distance ourselves from the threat. This is reiforcemnt learning on a world model. 

I'm imagining AGI as a 'perception model'. I'm sure there is a better name for it but this is what I'm calling it untill I know that name. This is a model that can interact with the world in many different ways and each time they recieve data input it gets 'embedded' (or something analagious happens) into the same space. Then the model uses this perception and turns it to an understanding then transforms the understanding to action (a transformation of the perception to action is uncousios behavior when then understanding to action can be called consious behaviour).
